{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direktori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 'D:/UTY/Semester 7/Pengembangan Aplikasi AI/Pengenal-Citra-Nomor-Kendaraan/Dataset/K1/'\n",
    "K2 = 'D:/UTY/Semester 7/Pengembangan Aplikasi AI/Pengenal-Citra-Nomor-Kendaraan/Dataset/K2/'\n",
    "K3 = 'D:/UTY/Semester 7/Pengembangan Aplikasi AI/Pengenal-Citra-Nomor-Kendaraan/Dataset/K3/'\n",
    "K4 = 'D:/UTY/Semester 7/Pengembangan Aplikasi AI/Pengenal-Citra-Nomor-Kendaraan/Dataset/K4/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan jalur ke direktori dataset\n",
    "dataset_dir = K1\n",
    "\n",
    "# Buat daftar semua berkas citra dalam direktori dataset\n",
    "berkas_citra = [os.path.join(dataset_dir, berkas) for berkas in os.listdir(dataset_dir) if berkas.endswith('.JPG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tetapkan nilai benih acak untuk konsistensi\n",
    "random.seed(42)\n",
    "\n",
    "# Tentukan rasio data untuk pelatihan dan pengujian\n",
    "rasio_pelatihan = 0.8  # 80% untuk pelatihan, 20% untuk pengujian\n",
    "\n",
    "# Bagi dataset menjadi set pelatihan dan pengujian\n",
    "berkas_pelatihan, berkas_pengujian = train_test_split(berkas_citra, train_size=rasio_pelatihan, test_size=1-rasio_pelatihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citra: 237\n",
      "Citra pelatihan: 189\n",
      "Citra pengujian: 48\n"
     ]
    }
   ],
   "source": [
    "# Buat direktori untuk dataset pelatihan dan pengujian jika belum ada\n",
    "direktori_pelatihan = os.path.join(dataset_dir, 'pelatihan')\n",
    "direktori_pengujian = os.path.join(dataset_dir, 'pengujian')\n",
    "os.makedirs(direktori_pelatihan, exist_ok=True)\n",
    "os.makedirs(direktori_pengujian, exist_ok=True)\n",
    "\n",
    "# Pindahkan berkas ke direktori yang sesuai\n",
    "for berkas in berkas_pelatihan:\n",
    "    tujuan = os.path.join(direktori_pelatihan, os.path.basename(berkas))\n",
    "    os.rename(berkas, tujuan)\n",
    "\n",
    "for berkas in berkas_pengujian:\n",
    "    tujuan = os.path.join(direktori_pengujian, os.path.basename(berkas))\n",
    "    os.rename(berkas, tujuan)\n",
    "\n",
    "# Cetak jumlah citra dalam masing-masing dataset\n",
    "print(f\"Total citra: {len(berkas_citra)}\")\n",
    "print(f\"Citra pelatihan: {len(berkas_pelatihan)}\")\n",
    "print(f\"Citra pengujian: {len(berkas_pengujian)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan jalur ke direktori dataset yang telah dibagi menjadi pelatihan dan pengujian\n",
    "direktori_pengujian = K1+'pengujian/'\n",
    "direktori_pelatihan = K1+'pelatihan/'\n",
    "\n",
    "# Tentukan direktori penyimpanan citra yang telah diproses\n",
    "direktori_pengujian_hasil = K1+'hasil/pengujian/'\n",
    "direktori_pelatihan_hasil = K1+'hasil/pelatihan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan preprocessing citra\n",
    "def preprocess_citra(berkas_citra):\n",
    "    # Baca citra dari berkas\n",
    "    citra = cv2.imread(berkas_citra)\n",
    "    \n",
    "    # Konversi citra ke skala abu-abu\n",
    "    citra = cv2.cvtColor(citra, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Konversi citra menjadi blur\n",
    "    citra = cv2.GaussianBlur(citra, (5, 5), 0)\n",
    "    \n",
    "    # Konversi citra menjadi B & W\n",
    "    citra = cv2.Canny(citra, 100, 200)\n",
    "    \n",
    "    # Mengubah ukuran citra menjadi lebih kecil\n",
    "    ukuran_citra = (500, 500)\n",
    "    citra = cv2.resize(citra, ukuran_citra)\n",
    "    \n",
    "    # # Ubah tipe data menjadi float32\n",
    "    # citra = citra.astype(np.float32) / 255.0  \n",
    "\n",
    "    \n",
    "    # Kembalikan citra yang telah diproses\n",
    "    return citra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess citra dalam direktori pelatihan\n",
    "for nama_berkas in os.listdir(direktori_pelatihan):\n",
    "    berkas_citra = os.path.join(direktori_pelatihan, nama_berkas)\n",
    "    citra_preprocessed = preprocess_citra(berkas_citra)\n",
    "    \n",
    "    # Simpan citra yang telah diproses ke direktori yang sama\n",
    "    nama_berkas_simpan = os.path.join(direktori_pelatihan_hasil, f'preprocessed_{nama_berkas}')\n",
    "    cv2.imwrite(nama_berkas_simpan, citra_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess citra dalam direktori pengujian\n",
    "for nama_berkas in os.listdir(direktori_pengujian):\n",
    "    berkas_citra = os.path.join(direktori_pengujian, nama_berkas)\n",
    "    citra_preprocessed = preprocess_citra(berkas_citra)\n",
    "    \n",
    "    # Simpan citra yang telah diproses ke direktori yang sama\n",
    "    nama_berkas_simpan = os.path.join(direktori_pengujian_hasil, f'preprocessed_{nama_berkas}')\n",
    "    cv2.imwrite(nama_berkas_simpan, citra_preprocessed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode Deteksi Plat Nomor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Fungsi untuk memuat dataset dan anotasinya\n",
    "def load_dataset(direktori):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for nama_berkas in os.listdir(direktori):\n",
    "        berkas_citra = os.path.join(direktori, nama_berkas)\n",
    "        citra = cv2.imread(berkas_citra, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Normalisasi piksel ke rentang 0-1\n",
    "        citra = citra / 255.0\n",
    "        \n",
    "        images.append(citra)\n",
    "        \n",
    "        # Ambil label dari nama berkas (contoh: \"plat\" atau \"non_plat\")\n",
    "        if \"plat\" in nama_berkas:\n",
    "            labels.append(1)  # 1 untuk plat\n",
    "        else:\n",
    "            labels.append(0)  # 0 untuk non-plat\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Memuat dataset pelatihan dan pengujian\n",
    "X_train, y_train = load_dataset(direktori_pelatihan_hasil)\n",
    "X_test, y_test = load_dataset(direktori_pengujian_hasil)\n",
    "\n",
    "# Membagi dataset pelatihan menjadi pelatihan dan validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menambahkan dimensi channel untuk input CNN\n",
    "X_train = X_train.reshape(X_train.shape + (1,))\n",
    "X_val = X_val.reshape(X_val.shape + (1,))\n",
    "X_test = X_test.reshape(X_test.shape + (1,))\n",
    "\n",
    "# Membangun model CNN sederhana\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model dengan data pelatihan dan validasi\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluasi model pada data pengujian\n",
    "hasil_evaluasi = model.evaluate(X_test, y_test)\n",
    "print(f'Akurasi pada data pengujian: {hasil_evaluasi[1]*100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
